
@article{benetos_automatic_2013,
	title = {Automatic music transcription: {Challenges} and future directions},
	volume = {41},
	shorttitle = {Automatic music transcription},
	doi = {10.1007/s10844-013-0258-3},
	abstract = {Automatic music transcription is considered by many to be a key enabling technology in music signal processing. However, the performance of transcription systems is still significantly below that of a human expert, and accuracies reported in recent years seem to have reached a limit, although the field is still very active. In this paper we analyse limitations of current methods and identify promising directions for future research. Current transcription methods use general purpose models which are unable to capture the rich diversity found in music signals. One way to overcome the limited performance of transcription systems is to tailor algorithms to specific use-cases. Semi-automatic approaches are another way of achieving a more reliable transcription. Also, the wealth of musical scores and corresponding audio data now available are a rich potential source of training data, via forced alignment of audio to scores, but large scale utilisation of such data has yet to be attempted. Other promising approaches include the integration of information from multiple algorithms and different musical aspects.},
	journal = {Journal of Intelligent Information Systems},
	author = {Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios and Kirchhoff, Holger and Klapuri, Anssi},
	month = dec,
	year = {2013},
	file = {Full Text PDF:/home/rand/Zotero/storage/4JRUEL5K/Benetos et al. - 2013 - Automatic music transcription Challenges and futu.pdf:application/pdf}
}

@book{brossier_automatic_2006,
	title = {Automatic {Annotation} of {Musical} {Audio} for {Interactive} {Applications}},
	author = {Brossier, Paul M.},
	year = {2006},
	file = {Citeseer - Snapshot:/home/rand/Zotero/storage/PNFK4EQD/summary.html:text/html;Citeseer - Full Text PDF:/home/rand/Zotero/storage/82FMYHF9/Brossier - 2006 - Automatic Annotation of Musical Audio for Interact.pdf:application/pdf}
}

@article{yeh_multiple_nodate,
	title = {Multiple {Fundamental} {Frequency} {Estimation} of {Polyphonic} {Recordings}},
	language = {en},
	author = {Yeh, Chunghsin},
	pages = {153},
	file = {Yeh - Multiple Fundamental Frequency Estimation of Polyp.pdf:/home/rand/Zotero/storage/HMBS4B73/Yeh - Multiple Fundamental Frequency Estimation of Polyp.pdf:application/pdf}
}

@article{goto_real-time_2004,
	title = {A real-time music-scene-description system: predominant-{F0} estimation for detecting melody and bass lines in real-world audio signals},
	volume = {43},
	issn = {01676393},
	shorttitle = {A real-time music-scene-description system},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167639304000640},
	doi = {10.1016/j.specom.2004.07.001},
	abstract = {In this paper, we describe the concept of music scene description and address the problem of detecting melody and bass lines in real-world audio signals containing the sounds of various instruments. Most previous pitch-estimation methods have had diﬃculty dealing with such complex music signals because these methods were designed to deal with mixtures of only a few sounds. To enable estimation of the fundamental frequency (F0) of the melody and bass lines, we propose a predominant-F0 estimation method called PreFEst that does not rely on the unreliable fundamental component and obtains the most predominant F0 supported by harmonics within an intentionally limited frequency range. This method estimates the relative dominance of every possible F0 (represented as a probability density function of the F0) by using MAP (maximum a posteriori probability) estimation and considers the F0Õs temporal continuity by using a multiple-agent architecture. Experimental results with a set of ten music excerpts from compact-disc recordings showed that a real-time system implementing this method was able to detect melody and bass lines about 80\% of the time these existed.},
	language = {en},
	number = {4},
	urldate = {2020-03-05},
	journal = {Speech Communication},
	author = {Goto, Masataka},
	month = sep,
	year = {2004},
	pages = {311--329},
	file = {Goto - 2004 - A real-time music-scene-description system predom.pdf:/home/rand/Zotero/storage/6MJL2ZRG/Goto - 2004 - A real-time music-scene-description system predom.pdf:application/pdf}
}

@article{de_cheveigne_multiple_1999,
	title = {Multiple period estimation and pitch perception model},
	volume = {27},
	issn = {0167-6393},
	url = {http://www.sciencedirect.com/science/article/pii/S0167639398000740},
	doi = {10.1016/S0167-6393(98)00074-0},
	abstract = {The pitch of a periodic sound is strongly correlated with its period. To perceive the multiple pitches evoked by several simultaneous sounds, the auditory system must estimate their periods. This paper proposes a process in which the periodic sounds are canceled in turn (multistep cancellation model) or simultaneously (joint cancellation model). As an example of multistep cancellation, the pitch perception model of Meddis and Hewitt, 1991a, Meddis and Hewitt, 1991b can be associated with the concurrent vowel identification model of Meddis and Hewitt (1992). A first period estimate is used to suppress correlates of the dominant sound, and a second period is then estimated from the remainder. The process may be repeated to estimate further pitches, or else to recursively refine the initial estimates. Meddis and Hewitt's models are spectrotemporal (filter channel selection based on temporal cues) but multistep cancellation can also be performed in the spectral or time domain. In the joint cancellation model, estimation and cancellation are performed together in the time domain: the parameter space of several cascaded cancellation filters is searched exhaustively for a minimum output. The parameters that yield this minimum are the period estimates. Joint cancellation is guaranteed to find all periods, except in certain situations for which the stimulus is inherently ambiguous.
Résumé
La hauteur d'un son périodique est étroitement liée à sa période. Pour percevoir les hauteurs multiples de plusieurs sons simultanés, le système auditif doit estimer leurs périodes. Cet article propose un processus d'estimation par lequel les sons périodiques sont annulés les uns après les autres (modèle d'annulation successive), ou simultanément (modèle d'annulation simultanée). Comme exemple de modèle d'annulation successive, le modèle de perception de la hauteur de Meddis et Hewitt (1991a,b) peut être associé au modèle d'identification de voyelles concurrentes de Meddis et Hewitt (1992). Une première estimation de la période sert à supprimer les corrélats du premier son, et la deuxième période est estimée à partir du reste de cette opération. L'opération peut être répétée pour estimer d'autres périodes, ou pour affiner les estimations initiales de façon récursive. Les modèles de Meddis et Hewitt sont de type spectro-temporel (sélection de canaux de filtre selon des critères temporels), mais l'annulation successive peut s'opérer aussi bien dans le domaine temps ou fréquence. Dans le modèle d'annulation simultanée, estimation et annulation se font ensemble dans le domaine temps: l'espace des paramètres d'une cascade de filtres d'annulation est parcouru exhaustivement, à la recherche d'un minimum du signal de sortie. Les paramètres de ce minimum sont les estimations des périodes. Le succès du modè le d'annulation simultanée est guaranti, sauf dans certaines situations où le stimulus est ambigu.},
	language = {en},
	number = {3},
	urldate = {2020-03-06},
	journal = {Speech Communication},
	author = {de Cheveigné, Alain and Kawahara, Hideki},
	month = apr,
	year = {1999},
	keywords = {Computational auditory scene analysis, Fundamental frequency, Pitch perception, Speech analysis},
	pages = {175--185},
	file = {ScienceDirect Snapshot:/home/rand/Zotero/storage/YDEP3AVT/S0167639398000740.html:text/html;de Cheveigné and Kawahara - 1999 - Multiple period estimation and pitch perception mo.pdf:/home/rand/Zotero/storage/BR9ZBRLL/de Cheveigné and Kawahara - 1999 - Multiple period estimation and pitch perception mo.pdf:application/pdf}
}